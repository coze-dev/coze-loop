models:
  - id: 1                    # Change It
    name: "your model name"  # Change It
    frame: "eino"
    protocol: "claude"
    protocol_config:
      api_key: "" # Change It。 Modify to the API Key you have already applied for
      model: ""   # Change It。 Modify to the model ID you have already activated
    param_config: # Usually no modifications are needed, as this determines which parameters are adjustable on the front end, their adjustable ranges, and default values.
      param_schemas:
        - name: "temperature"
          label: "temperature"
          desc: "Increasing the temperature will make the model output more diverse and creative. Conversely, lowering the temperature will make the output more compliant with instructions but less diverse. It is recommended not to adjust together with 'Top p'."
          type: "float"
          min: "0"
          max: "1.0"
          default_val: "0.7"
        - name: "max_tokens"
          label: "max_tokens"
          desc: "Controls the maximum length of tokens output by the model. Typically, 100 tokens are approximately equal to 150 Chinese characters."
          type: "int"
          min: "1"
          max: "4096"
          default_val: "2048"
        - name: "top_p"
          label: "top_p"
          desc: "During generation, selects the smallest set of tokens whose cumulative probability reaches top_p. Tokens outside the set are excluded, balancing diversity and reasonableness."
          type: "float" #
          min: "0.001"
          max: "1.0"
          default_val: "0.7"

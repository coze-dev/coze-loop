{
  "evaluate_run_trajectory": "running track",
  "evaluate_evaluated_object_actual_output_traj": "The actual output trajectory of the evaluation object",
  "evaluate_trajectory_visualization": "Trajectory visualization",
  "evaluate_evaluated_object_output_data": "evaluation object output data",
  "evaluate_select_scenario_one_click_config": "Select a scene for one-click quick configuration",
  "evaluate_quick_configuration": "Quick configuration",
  "evaluate_ideal_output_evaluation_set": "Ideal Output Evaluation Set",
  "evaluate_include_input_and_ideal_output": "Includes input and ideal output",
  "evaluate_excessively_long_data": "Very long data",
  "evaluate_data_not_meet_traj_format": "The data does not conform to the track format",
  "evaluate_agent_execution_data_follow_structure": "Agent executes process data and follows the specified data structure.",
  "evaluate_what_makes_you_satisfied": "What do you think satisfies you?",
  "evaluate_specifically_satisfied_experience": "Tell me specifically about your satisfactory experience.",
  "evaluate_data_row_id_not_passed_correctly": "Row ID not passed correctly",
  "runtime_indicators": "runtime metrics",
  "eval_field_mapping_error_tips": "The selected field type on the right is incompatible and cannot be consumed directly. Please select again.",
  "eval_target_total_latency_tips": "Total elapsed time (ms) from request to complete response for the evaluation object",
  "eval_target_input_tokens_tips": "Total consumption of model call input tokens during evaluation object execution",
  "eval_target_output_tokens_tips": "Total consumption of model call output tokens during evaluation object execution",
  "eval_target_total_tokens": "Total Tokens Consumption of Model Calls During Object Execution",
  "evaluate_code_evaluator_default_js_code_list": "function exec_evaluation(eval_input) {\n  // 在这里编写你的评估逻辑\n  // input: 输入数据\n  // output: 模型输出\n  // expected: 期望输出\n\n  // 返回评估结果对象\n  return {\n    score: 1.0, // 分数 (0-1)\n    description: \"评估通过\"\n  };\n}",
  "evaluate_code_evaluator_default_python_code_list": "def exec_evaluation(eval_input):\n    \"\"\"\n    在这里编写你的评估逻辑\n    input: 输入数据\n    output: 模型输出\n    expected: 期望输出\n\n    返回评估结果字典\n    \"\"\"\n    return {\n        \"score\": 1.0,  # 分数 (0-1)\n        \"description\": \"评估通过\"\n    }",
  "evaluate_code_evaluator_default_js_code": "function exec_evaluation(turn) {\n  /** 检查turn中某字段是否等于目标值（仅处理Equals规则） */\n  const TARGET_VALUE = \"Text\";\n\n  try {\n    // 直接访问目标字段\n    const current = turn.turn.actual_output.text;\n\n    const isEqual = current === TARGET_VALUE;\n    const score = isEqual ? 1.0 : 0.0;\n    const reason = `字段'turn.actual_output.text'的值为'${current}'，与目标值'${TARGET_VALUE}'${isEqual ? '相等' : '不相等'}`;\n\n    return { score, reason };\n  } catch (e) {\n    if (e instanceof TypeError || e instanceof ReferenceError) {\n      return { score: 0.0, reason: `字段路径不存在：${e.message}` };\n    }\n    return { score: 0.0, reason: `检查出错：${e.message}` };\n  }\n}\n",
  "evaluate_evaluation_new_llm_evaluator": "Evaluation - Create New LLM Evaluator",
  "evaluate_evaluation_new_code_evaluator": "Evaluation - Create New Code Evaluator",
  "evaluate_question_particle": "?",
  "evaluate_column_irreversible_action": "column, this operation is irreversible",
  "evaluate_evaluation_new_testset": "Evaluation - Create New Test Set",
  "evaluate_case_info_desc": "Description:",
  "evaluator_provider": "Provider",
  "help_documentation": "Help Documentation",
  "evaluator_filter": "Evaluator filter",
  "evaluator_evaluation_object": "Evaluation object",
  "evaluator_objectives": "Evaluator objectives",
  "business_scenario": "Business Scenario",
  "custom_create_{type}_evaluator": "Customize the creation of {type} assessors",
  "evaluator_template": "Evaluator template",
  "evaluator_template_filter_empty_tips": "No relevant results were found in the current filtering state",
  "total_{num}_items": "A total of {num} items",
  "evaluator_search_placeholder": "Search for indicator names",
  "evaluate_no_evaluator_desc": "No evaluator description available",
  "evaluate_search_evaluator": "Search Evaluator",
  "evaluate_preset_no_new": "The preset evaluator does not support new creation",
  "evaluator_detail": "Evaluator Detail",
  "application_scene": "Application Scene",
  "evaluate_taiwan_geography_overview": "Taiwan Province is composed of China's largest island Taiwan Island and more than 80 affiliated islands including Orchid Island, Green Island, Diaoyu Islands, and the Penghu Archipelago, covering a total area of about 36,000 square kilometers. Among them, Taiwan Island is about 35,800 square kilometers.",
  "evaluate_code_validating": "Code validating...",
  "evaluate_submit_after_code_syntax_passed": "You can submit after the code syntax check passes",
  "evaluate_code_check_passed": "Code check passed",
  "evaluate_code_syntax_correct_can_submit": "Code syntax is correct, you can submit",
  "evaluate_code_check_failed_retry": "Code check failed, please try again",
  "evaluate_view_actual_output_trace": "View trace of actual output",
  "evaluate_turn_represents_single_round_evaluation": "Turn represents the evaluation scenario of a single-round Q&A, as follows:",
  "evaluate_evaluate_dataset_fields_desc": "evaluate_dataset_fields: Evaluation dataset fields",
  "evaluate_evaluate_target_output_fields_desc": "evaluate_target_output_fields: Fields of evaluation targets",
  "evaluate_ext_additional_fields": "ext: Supplementary fields",
  "evaluate_please_refer_to_details": "Please refer to detailed information",
  "evaluate_select_data_placeholder1_maxcount": "Select data ({placeholder1}/{maxCount})",
  "evaluate_loading_data": "Loading data...",
  "evaluate_direct_import": "Direct import",
  "evaluate_simulated_data": "Simulated data",
  "evaluate_previous_step_associate_targets": "Previous step: Associate evaluation targets",
  "evaluate_previous_step_dataset_config": "Previous step: Evaluation dataset configuration",
  "evaluate_next_step_generate_simulated_output": "Next step: Generate simulated output",
  "evaluate_no_run_output": "No running output available",
  "evaluate_score_points": "{score} points",
  "evaluate_reason_label": "Reason: ",
  "evaluate_no_run_result": "No execution results available",
  "evaluate_click_test_run_to_start": "Click the test run button to start testing",
  "evaluate_test_running": "Test running...",
  "evaluate_test_run_result": "Test run result",
  "evaluate_experiment_incomplete_export_not_supported": "The current experiment is not completed, export and download are not supported",
  "evaluate_export_file_max_100_days": "Exported files are saved for a maximum of 100 days; after expiration, you need to export again before downloading.",
  "evaluate_export_in_progress_wait": "Export in progress, please wait for completion before trying again",
  "evaluate_export_failed_retry": "Export failed, please export again",
  "evaluate_export_file_expired_100_days": "Exported file storage is limited to 100 days and has expired",
  "evaluate_selected_label": "Selected:",
  "evaluate_version_description": "Version description",
  "evaluate_evaluation_experiment_creation": "Evaluation - Experiment creation",
  "evaluate_create_evaluator": "Create evaluator",
  "evaluate_copy_placeholder1_config_create_evaluator": "Copy {placeholder1} configuration and create a new evaluator",
  "evaluate_confirm_delete_evaluator_placeholder1": "Are you sure to delete evaluator: {placeholder1}?",
  "evaluate_please_select_cozebot": "Please select CozeBot",
  "evaluate_please_select_prompt": "Please select Prompt",
  "evaluate_compare_experimentCount_experiments": "Compare {experimentCount} experiments",
  "evaluate_skip_target_execution_config": "Skip evaluation target execution configuration, suitable for evaluation datasets that already contain actual agent outputs.",
  "evaluate_skip_evaluator_config_manual_labeling": "Choose to skip evaluator configuration; experiment only obtains actual agent output, for scenarios with manual annotation.",
  "evaluate_evaluator_configuration": "Evaluator configuration",
  "evaluate_loading_failed": "Loading failed",
  "evaluate_evaluator_not_exist": "Evaluator does not exist",
  "evaluate_confirm_to_remove": "Confirm removal",
  "evaluate_please_select_target_version": "Please select evaluation target version",
  "evaluate_experiment_concurrent_execution_limitations": "Experiments support concurrent execution of entries in the evaluation dataset, but are limited by the concurrency of evaluation targets and the TPM limits of calling evaluators' models. Set the ideal maximum execution count here.",
  "evaluate_view_trace": "View trace",
  "evaluate_please_input_keyword_search_max_length": "Please enter keyword search, maximum {MAX_SEARCH_LENGTH} characters",
  "evaluate_keyword_search_max_length_truncated": "Keyword search limited to {MAX_SEARCH_LENGTH} characters, excess part has been automatically truncated",
  "evaluate_data_item_id": "Data item ID",
  "evaluate_please_input_max_limitLength_chars": "Please enter, up to {limitLength} characters",
  "evaluate_input_content_max_limitLength_truncated": "Input content limited to {limitLength} characters, excess part has been automatically truncated",
  "evaluate_invalid_id_must_be_limitLength": "ID is invalid, must be {limitLength} characters",
  "evaluate_complete_label_data_annotation_then_refresh": "After completing all data annotation for this tag, please refresh and try again",
  "evaluate_intelligent_synthesis": "Intelligent synthesis",
  "evaluate_data_synthesis_text_only": "Generalize, augment, and synthesize new data based on evaluation datasets or online real data; only flexible augmentation operations on text evaluation datasets are supported.",
  "evaluate_max_support_50_columns": "Supports up to 50 columns",
  "evaluate_confirm_batch_delete_placeholder1_experiments": "Are you sure to batch delete {placeholder1} experiment data? This operation is irreversible.",
  "evaluate_please_select_evaluation_experiment": "Please select evaluation experiment",
  "evaluate_reevaluate_failed_and_unexecuted_only": "Re-evaluate only failed and unexecuted parts",
  "evaluate_terminate_running_experiment": "Terminate running experiment",
  "evaluate_reevaluate_failed_and_unexecuted_only_period": "Re-evaluate only failed and unexecuted parts.",
  "evaluate_terminate_experiment": "Terminate experiment",
  "evaluate_confirm_terminate_running_experiment": "Are you sure you want to terminate the running experiment? This operation is irreversible.",
  "evaluate_preset_array_object_data_type": "Preset Array<Object> data type, Object data structure is as follows. Suitable for managing mixtures of various modal data such as images and text.",
  "evaluate_reason_colon": "Reason:",
  "evaluate_please_input_float_max_4_decimal": "Please enter a float with up to 4 decimal places",
  "evaluate_please_select_prompt_key": "Please select Prompt key",
  "data_engine_info_unsaved": "Information not saved",
  "data_engine_confirm_close_warning": "You will lose unsaved content upon closing. Confirm to close?",
  "data_engine_data_count_text": "amount of data",
  "data_engine_max_preview": "Supports up to the first {maxPreview} data to be previewed",
  "user_input": "User input",
  "minus_evaluation_dataset": "- Evaluation set",
  "column_count_info": "(Total {currentColumnNum}/50 columns)",
  "cozeloop_open_evaluate_column_braces_irreversible": "{ } column, this operation is irreversible",
  "cozeloop_open_evaluate_data_type_mismatch_instancepath": "{instancePath} data type does not match field definition",
  "x_items": "{item, plural, zero {No item} one {1 item} other {# items}}",
  "x_score": "{num} score",
  "cozeloop_open_evaluate_template_placeholder0": "{placeholder0} template",
  "placeholder0_details": "Details of {placeholder0}",
  "cozeloop_open_evaluate_score_placeholder1": "{placeholder1} points",
  "evaluate_code_evaluator_detail": "Code Evaluator Detail",
  "evaluate_code_evaluator": "Code Evaluator",
  "evaluate_test_data_tutorial_link": "Code Evaluator Manual",
  "coze_bot": "Coze Bot",
  "coze_workflow": "Coze Workflow",
  "coze_agent": "Coze Agent",
  "csv_format": "CSV format",
  "id_invalid_must_be_limit_length": "The ID is invalid. It must be {limitLength} digits long.",
  "cozeloop_open_evaluate_json_schema_format_error": "JSON Schema format error",
  "cozeloop_open_evaluate_json_schema_type_mismatch": "JSON Schema data type does not match the column type, please modify",
  "cozeloop_open_evaluate_json_format_error": "JSON format error",
  "evaluate_json_parse_error": "JSON Parse Error:",
  "evaluate_json_serialize_error": "JSON Serialize Error:",
  "evaluate_llm_evaluator": "LLM Evaluator",
  "prompt_detail": "Prompt detail",
  "schema_mismatch": "Schema mismatch",
  "system_prompt_not_empty": "The System Prompt cannot be empty",
  "user_prompt_required": "The User Prompt cannot be empty.",
  "encyclopedia_expert": "Encyclopedia expert",
  "pedia_dataset": "Encyclopedic dataset ${index}",
  "version_cannot_be_empty": "The version cannot be empty",
  "version_format_and_range": "The version format is a.b.c, and each segment ranges from 0 to 999.",
  "version_number": "Version number",
  "version_number_gt_current": "The version number must be greater than the latest version number: {version}",
  "version_number_format": "The version number is in the format of a.b.c, and each segment ranges from 0 to 9999",
  "version_submit_success": "Version submitted",
  "contains_illegal_content": "Contains illegal content",
  "evaluation_set_save_and_continue": "Save and continue",
  "evaluate_save_failed_please_retry": "Save Failed, Please Retry",
  "evaluate_save_failed": "Save Failed:",
  "local_import": "Local import",
  "evaluate_programming_language": "Programming Language",
  "edit_column": "Edit column",
  "cozeloop_open_evaluate_edit_column": "Edit column:",
  "edit_evaluation_set": "Edit evaluation set",
  "edit_evaluator": "Edit evaluator",
  "edit_experiment": "Edit the experiment",
  "edit_data_item": "Edit data items:",
  "annotation_aggregate_score": "Mark the aggregated score.",
  "evaluate_form_validation_failed": "Form Validation Failed:",
  "not_contain": "Does not contain",
  "do_not_save": "Don't save",
  "not_equal_to": "Is not equal to",
  "parameter_details": "Parameter details",
  "evaluate_parameter_injection": "Parameter injection",
  "application_operator": "Operator",
  "draft_version": "Draft version",
  "cannot_modify_data_type_tip": "There are existing data items in the draft version, and modification of the data type is not supported.",
  "draft_auto_saved_date": "The draft has been automatically saved on {date}.",
  "draft_auto_save_failed": "Auto-saving of the draft failed.",
  "draft_auto_saving": "Draft is being automatically saved.",
  "evaluate_test_data_turn": "Test Data: turn",
  "view_tag_details": "View the details of the tag",
  "view_and_download_files": "View and download files",
  "view_parameters": "View parameters",
  "view_format": "View the format",
  "view_evaluator_trace": "View the Trace of evaluator",
  "view_evaluator_details": "View the details of the evaluator",
  "view_actual_output_trace": "Check the actual output trace",
  "view_data_item": "View data items:",
  "loop_view_details": "View details:",
  "evaluate_success_{success_count}_fail_{fail_count}": "{success_count} successes, {fail_count} failures",
  "add_x_data_item_success": "Add {num} data items success",
  "successfully_added_{successcount}_data": "Successfully added {successCount} pieces of data",
  "eat_fish": "Eat fish",
  "evaluate_dataset_info_creator": "Creator:",
  "this_step_skipped": "This step has been selected to be skipped.",
  "this_step_skipped_period": "This step has been selected to be skipped.",
  "this_operation_is_irreversible": "This operation is irreversible",
  "caution_of_operation": "Caution: This operation is irreversible. Please proceed carefully.",
  "evaluate_add_data_from_evaluation_set": "Add Data from Evaluation Set",
  "there_is_redundant_field": "There are redundant fields",
  "cozeloop_open_evaluate_redundant_field_exists": "Redundant field {placeholder1} exists",
  "failure_reasons_and_retry": "Execution failed due to the following reasons, please correct them and try again",
  "greater_than": "Greater than",
  "evaluate_code_content": "Code Content",
  "evaluate_code_evaluator_created_successfully": "Code Evaluator Created Successfully",
  "source_column_mapping": "The mapping relationship between the column names of the data to be imported and the column names of the current evaluation set.",
  "to_be_executed": "Pending execution",
  "single_max_add_data_items": "A maximum of {num} data items can be added at one time.",
  "cozeloop_open_evaluate_max_10_data_items_per_add": "Maximum 10 data items can be added at once",
  "single_data_size_exceeded": "Single data size exceeds the limit",
  "evaluation_set_json_schema_invalid_tips": "The current JSON Schema is invalid. Switching will result in the loss of configuration. Do you want to continue switching?",
  "draft_unsubmitted_tip": "There are unsubmitted changes in the current draft. The latest historical version has been selected by default",
  "export_not_supported_incomplete_experiment": "The current experiment is not completed. Exporting and downloading are not supported.",
  "evaluate_export": "Export",
  "export_format": "Export format",
  "evaluate_export_records": "Export records",
  "export_in_progress_wait": "Export is in progress. Please try again after the export is completed.",
  "export_task_id": "Export task ID",
  "evaluate_export_failed": "Export failed",
  "export_failed_retry": "Export failed. Please export again.",
  "cozeloop_open_evaluate_export_experiment_details": "Export experiment details",
  "export_data": "Export data",
  "export_file_expired_100_days_limit": "The exported files can be stored for a maximum of 100 days and have already expired.",
  "export_files_save_limit_100_days": "Exported files can be saved for a maximum of 100 days. After expiration, you need to export them again and then download.",
  "model_exporting": "Exporting",
  "cozeloop_open_evaluate_export_in_progress_view": "Exporting, view",
  "export_status": "Export status",
  "import_method": "Import method",
  "import_data": "Import data",
  "importing_data_will_overwrite_existing_data": "Importing data will overwrite the existing data",
  "evaluation_set_import_error_data_type_tips": "The data type of the imported data does not match the data type of the column, so the data cannot be imported.",
  "import_data_column": "Import data column",
  "cozeloop_open_evaluate_remove_fields_outside_structure_on_import": "Whether to remove fields outside the data structure definition when importing data",
  "cozeloop_open_evaluate_data_processing_after_validation_import": "Data processing operations after completing validation when importing data.",
  "import_sample_data": "Import sample data",
  "import_approved_images": "Import via the passed picture",
  "score_is": "Score:",
  "score_only_for_preview": "The score shown is for preview purposes only and does not represent the actual result.",
  "score_reason": "Reasons for scoring",
  "score_details": "Score detail",
  "score_details_data_item_distribution": "Score details - Data item distribution",
  "equal_to": "Equal to",
  "click_or_drag_file_to_upload": "Click to upload or drag files here",
  "click_to_create": "Click the 'Create' button in the upper right corner to create.",
  "cozeloop_open_evaluate_click_export_button_top_right": "Click the export button in the top right corner to export",
  "click_to_add_data": "Click the 'Add Data' button in the top-right corner to add.",
  "click_to_create_evaluation_set": "Click the \"New Evaluation Set\" button in the upper right-hand corner to create.",
  "click_to_create_experiment": "Click the \"New Experiment\" button in the upper right corner to create.",
  "cozeloop_open_evaluate_click_autocomplete_all_fields": "Click to auto-complete all fields in this data structure",
  "cozeloop_open_evaluate_dynamic_parameters": "Dynamic parameters",
  "compare_x_experiments": "{num, plural, zero {No experiment to compare} one {Compare 1 experiment} other {Compare # experiments.}}",
  "compare_placeholder1_experiments": "Compare {placeholder1} experiments.",
  "compare_experiment_detail": "Compare experiment detail",
  "initiate_experiment": "Initiate an experiment",
  "run_experiment_comparison": "Run experiment comparison",
  "cozeloop_open_evaluate_copy_with_id": "Copy {idString}",
  "copy_and_create_evaluator": "Copy the config of {name} and create a new evaluator",
  "copy_and_run_experiment": "Copy the {name} configuration, or modify the configuration and start the experiment.",
  "copy_evaluator_config": "Copy the evaluator config",
  "copy_experiment_config": "Duplicate the experimental config",
  "copy_and_create_experiment": "Duplicate the experiment configuration and create a new experiment.",
  "dataset_ai_annotation_prompt_config_override": "Override Prompt model configuration",
  "cozeloop_open_evaluate_tag_option_disabled_no_longer_selectable": "This tag option has been disabled, if modified it will no longer be selectable",
  "evaluate_tag_disabled_no_modification": "This tag has been disabled and modification is not allowed.",
  "workflow_associated_coze_agent_id": "The ID of the application associated with this workflow",
  "the_field_required": "The field is required",
  "advanced_validation_rule": "Advanced verification rules",
  "evaluate_living_habits_animal": "Tell me about the living habits of this animal",
  "format_json": "Format JSON",
  "update_success": "Update succeed",
  "update_rating_success": "Score updated",
  "evaluation_set_workflow_params_tips": "You can view the input parameters and their values of the start node of the workflow, as well as the parameter list, on the orchestration page of the specified workflow",
  "workflow_need_associated_coze_agent_id": "The ID of the Coze agent that the workflow needs to be associated with",
  "total_of_columns": "Totally {num}/{total} columns",
  "construct_test_data": "Construct test data",
  "cozeloop_open_evaluate_disable_redundant_validation_default_no": "After disabling, redundant field validation configuration will use default configuration \"No\", confirm disable?",
  "keyword_search_length_limited_truncated": "The maximum length for keyword search is {MAX_SEARCH_LENGTH} characters. The part exceeding this length has been automatically truncated.",
  "associated_evaluation_set": "Related evaluation set",
  "associated_experiment": "Related experiments",
  "you_can_use_this_function_later": "You can use this function later",
  "get_evaluation_object_error": "An error occurred while obtaining the evaluation object",
  "evaluate_failed_to_get_evaluation_set_data": "Failed to Get Evaluation Set Data:",
  "basic_information": "Basic information",
  "evaluate_based_on_evaluation_set": "Based on Evaluation Set",
  "automatic_extraction_of_data_structure_based_on_sample_data": "Automatically extract data structures based on sample data",
  "benchmark_experiment_switch_success": "The benchmark experiment has been switched.",
  "benchmark_group": "Baseline group",
  "continue_will_override_existing_data": "Continuing to import data will overwrite the existing data",
  "evaluate_check": "Check",
  "interface_problem": "Request problem",
  "end_time": "End time",
  "only_experiments_compared_tip": "Only completed experiments with the same evaluation set can be compared.",
  "experiments_compared_tip": "Only experiments with the same evaluation set and completed execution can be compared. The currently selected experiments involve different associated evaluation sets. Please reselect.",
  "only_completed_experiments_can_be_compared": "Only completed experiments can be compared. Please make a new selection.",
  "re_evaluate_failed_only": "Re-evaluate only the parts that failed to execute.",
  "only_re_evaluate_failed_part": "Re-evaluate only the parts that failed to execute.",
  "cozeloop_open_evaluate_export_only_final_state_experiments": "Only supports exporting experiments in final state (success or failure)",
  "decimal_places_support": "Only support precision up to {num} decimal places",
  "data_engine_decimal_places_support": "Only supports precision up to {placeholder1} decimal places",
  "support_precision": "Only {precision} decimal places of precision are supported.",
  "support_letter_number_underscore_start_letter": "Only supports English, numbers, underscores, and must start with a letter",
  "support_letter_number_chinese_special_char": "Only supports English letters, numbers, Chinese characters, \"-\", \"_\", \".\"",
  "support_letter_number_chinese_start": "Only supports starting with English letters, numbers, or Chinese characters",
  "compact_view": "Compact view",
  "in_progress": "In progress",
  "aggregation_score": "Aggregation score",
  "cozeloop_open_evaluate_enable_object_type_validation_rules": "When enabled, Object data type supports configuring validation rules to control whether data is allowed when importing data if there are fields outside the Object data structure definition",
  "start_time": "Start time",
  "visual_configuration": "Visualization configuration",
  "construct_data_to_preview": "Preview the evaluator's output by constructing test data.",
  "empty_data": "Empty data",
  "quick_annotation_mode": "Quick annotation mode",
  "loose_view": "Loose View",
  "evaluate_blue_whale": "Blue whale",
  "leave_page_tip": "Leaving the current page will result in the information not being saved.",
  "leave_current_page_information_will_not_be_saved": "The information will not be saved after leaving",
  "user_lisi": "Li Si",
  "column_index": "Column {index}",
  "column_description": "Column description",
  "column_name_exists": "The column name already exists",
  "column_mapping": "Column mapping",
  "this_change_irreversible": "? This change is irreversible.",
  "description_is": "Description: {desc}",
  "name_and_version": "Name and version",
  "name_already_exists": "Name already exists",
  "model_selection": "Model selection",
  "generated_by_ai_tip": "The content is generated by AI. Its authenticity and accuracy cannot be guaranteed and it is for reference only.",
  "evaluate_you_can_use_directly": "You can use directly",
  "evaluate_config": "Configuration",
  "cozeloop_open_evaluate_config_and_launch_experiment": "configuration, launch experiment directly or after modifying configuration.",
  "configuration_column": "Config columns",
  "config_info": "Config info",
  "batch_delete_experiment": "Batch delete experiments",
  "bulk_select": "Bulk select",
  "evaluation_object": "Evaluation object",
  "evaluation_object_version": "Version of the evaluated object",
  "evaluation_object_actual_output": "Actual output of the evaluation object",
  "evaluate_target_type": "Evaluation object type",
  "evaluation_set_version": "Evaluation set version",
  "can_still_modify_column": "Column configuration can still be modified after the evaluation set is created.",
  "evaluation_set_column": "Evaluation set columns",
  "evaluation_set_description": "Evaluation set description",
  "evaluation_set_name": "Evaluation set name",
  "evaluation_set_data": "Evaluation set data",
  "evaluation_set_field_mapping_tip": "This mapping connects evaluation set fields and actual outputs of evaluation objects to evaluator fields, enabling the evaluator to accurately obtain inputs for evaluation.",
  "evaluation_set_field_to_evaluation_object_field_mapping": "Mapping from evaluation set fields to evaluation object fields, enabling evaluation objects to accurately acquire inputs",
  "evaluator_score": "Evaluator score",
  "evaluator_aggregate_score": "Evaluator aggregated score",
  "evaluator_type": "Evaluator type",
  "evaluator_name": "Evaluator name",
  "evaluator_lacks_input": "The evaluator lacks input",
  "evaluate_validation_passed": "Validation Passed",
  "prompt_compare_normal": "Normal mode",
  "cozeloop_open_evaluate_array_object_data_sample_multimodal": "Its Array<Object> data sample is as follows, commonly seen in Model span in multimodal scenarios.",
  "analytics_subtitle_others": "Others; Other things; The rest",
  "switching_modification_overwritten_tips": "The current modifications will be overwritten after switching",
  "clear_filter": "Clear filters",
  "evaluate_please_write_function_body": "Please Write Function Body",
  "try_other_keywords": "Please try other keywords or modify the filter options",
  "evaluate_please_configure_test_data": "Please Configure Test Data",
  "please_configure_the_import_column": "Please configure the import columns",
  "configure_column_mapping": "Please configure column mapping",
  "config_evaluation_object_mapping": "Please config the evaluation object mapping",
  "please_configure_field_mapping": "Please configure field mapping",
  "configure_at_least_one_import_column": "Please configure at least one import column",
  "cozeloop_open_evaluate_inject_parameters_for_evaluation_request": "When requesting evaluation objects, you can inject filled parameters to get the output results of evaluation objects. Such as request environment lanes, test account UID, etc.",
  "upload_file": "Please upload the file",
  "please_enter_max_limit_length": "Please enter, with a maximum of {limitLength} characters.",
  "please_enter_id_limit_length": "Please enter a {limitLength}-digit ID.",
  "please_enter_a_number_in_the_range_{num1}_to_{num2}": "Please enter a number in the range of {num1} to {num2}",
  "input_number_between_0_and_1": "Please enter a number in the range of 0 to 1",
  "input_score_between_0_and_1": "Please enter a score between 0 and 1",
  "cozeloop_open_evaluate_enter_integer": "Please enter integer",
  "please_input_version_number": "Please input version number",
  "please_enter_tag_name_search": "Please enter the tag name to search.",
  "cozeloop_open_evaluate_enter_number_greater_equal_minimum": "Please enter a number greater than or equal to {minimum}",
  "input_num_gte": "Please enter a number greater than or equal to {num}",
  "please_enter_an_object": "Please enter the object",
  "input_float_with_precision": "Please enter a float with at most 4 decimal places.",
  "enter_keyword_search_max_length": "Please enter keywords for retrieval, with a maximum of {MAX_SEARCH_LENGTH} characters.",
  "enter_column_description": "Please enter the column description",
  "please_enter_column_name": "Please enter the column name",
  "please_input_name": "Please input name",
  "please_enter_content": "Please enter the content",
  "please_enter_a_review_set_description": "Please enter the description of the evaluation set",
  "enter_evaluation_name": "Please enter the name of the evaluation set",
  "please_enter_a_value": "Please enter a value",
  "please_enter_the_picture_link": "Please enter the picture link",
  "cozeloop_open_evaluate_enter_text_content": "Please enter text content",
  "cozeloop_open_evaluate_enter_number_less_equal_maximum": "Please enter a number less than or equal to {maximum}",
  "input_num_lte": "Please enter a number less than or equal to {num}",
  "please_enter_a_valid_url": "Please enter a valid URL",
  "please_enter_the_reason": "Please enter the reason",
  "enter_integer": "Please enter an integer",
  "eval_version_number_format": "Please enter the correct version in the format a.b.c, where each segment is between 0 and 999.",
  "please_add_evaluator": "Please add evaluator",
  "please_select_prompt_key": "Please select Prompt Key",
  "select_prompt_key_and_version_to_view": "Select Prompt key and version to view",
  "select_version": "Please select a version.",
  "please_select_a_version_number": "Please select the version number",
  "cozeloop_open_evaluate_please_select_export_format": "Please select export format",
  "select_import_method": "Please select the import method",
  "select_type": "Please select type",
  "choose_model": "Please select a model",
  "please_select_evaluate_target": "Please select the evaluation object",
  "evaluate_please_select_target_and_version": "Please Select Target and Version",
  "select_evaluation_set": "Please select the evaluation set",
  "please_select_evaluation_set_version": "Please select the evaluation set version",
  "please_select_evaluator": "Please select an evaluator",
  "select_evaluator_and_version_number_to_view": "Please select an evaluator and a version number before viewing",
  "select_data_type": "Please select the data type",
  "please_select_an_indicator": "Please select an indicator",
  "please_add_at_least_one_image_link": "Please add at least one image link",
  "go_submit": "Submit now",
  "overwrite_data": "Overwrite",
  "evaluate_full_screen": "Full Screen",
  "missing_required_field": "Missing required fields",
  "cozeloop_open_evaluate_missing_required_field": "Missing required field \"{placeholder1}{placeholder2}\"",
  "confirm_to_delete_x": "Are you sure to delete {name} ? This modification is irreversible.",
  "cozeloop_open_evaluate_confirm_delete_evaluation_set": "Confirm delete evaluation set",
  "evaluation_set_{name}_delete_tips": "Are you sure you want to delete the evaluation set {name}? This change is irreversible.",
  "confirm_to_delete_evaluation_set": "Confirm to delete evaluation set {name} ? This operation is irreversible.",
  "confirm_delete_evaluator": "Confirm to delete the evaluator: {name}?",
  "confirm_delete_data_items": "Confirm to delete the data item",
  "confirm_to_delete_data_item": "Are you sure to delete data item {name} ? This modification is irreversible.",
  "cozeloop_open_evaluate_confirm_to_delete": "Confirm to delete",
  "confirm_to_delete_selected_data_item": "Are you sure to delete {num} selected data items ? This modification is irreversible.",
  "global_btn_confirm": "Confirm",
  "confirm_batch_delete_x_experiment": "Are you sure to delete {num} experimental data entries in batch? This modification is irreversible.",
  "confirm_the_switch": "Confirm the switch",
  "cozeloop_open_evaluate_confirm_switch": "Confirm switch?",
  "confirm_clear_prompt": "Confirm to clear the Prompt?",
  "delete_confirm": "Confirm deletion",
  "confirm_delete_user_prompt": "Confirm to delete the User Prompt?",
  "confirm_delete_x_columns": "Confirm to delete {num} columns. This operation is irreversible.",
  "cozeloop_open_evaluate_confirm_delete_selected_data_irreversible": "Confirm delete selected {placeholder1} data items? This operation is irreversible",
  "confirm_experiment_config": "Confirm the experiment config",
  "confirm_the_extracted_data_structure": "Confirm the extracted data structure",
  "confirm_full_overwrite": "Confirm the selection of full coverage",
  "confirm_removal": "Confirm to remove {field} ?",
  "confirm_to_remove_x": "Confirm to remove {name} ?",
  "confirm_evaluation_set_version": "Confirm the version of the evaluation set used for the experiment",
  "manual_annotation_management": "Manual annotation management",
  "manual_calibration": "Manual calibration",
  "redundant_field_check": "Redundant field verification",
  "saved_lost_data_tips": "If you don't save, the edited information will be lost",
  "no_mapping_no_import": "Columns in the dataset to be imported will not be imported if no mapping relationship is configured for them.",
  "evaluate_import_data_from_eval_set_with_output_tip": "You can directly import selected data if your evaluation set already contains target output",
  "how_to_create_a_review_set": "How to create an evaluation set?",
  "delete_user_prompt": "Delete User Prompt",
  "delete_tag": "Delete the tag",
  "delete_this_tag": "Delete this tag.",
  "deleting_tag_affects_labeled_content": "Deleting this tag will affect the tagged content.",
  "delete_column": "Delete the column",
  "delete_review_set": "Delete the evaluation set",
  "delete_experiment": "Delete experiment",
  "delete_data_item": "Delete data item",
  "upload_fail": "Upload failed",
  "upload_failed_please_try_again": "Upload failed. Please try again",
  "upload_data": "Upload data",
  "cozeloop_open_evaluate_image_upload_failed": "Image upload failed",
  "cozeloop_open_evaluate_uploading": "Uploading...",
  "prev_step": "Prev step",
  "wait_a_few_seconds": "Wait for a few seconds and then...",
  "wait_and_refresh_page": "Wait a few seconds and then {refresh} the page to view.",
  "upgrade_enterprise_team_edition_package": "Upgrade the \"\"Enterprise Team Edition Package\"\"",
  "evaluate_generate_mock_output": "Generate Mock Output",
  "failure_count_fail_turn_cnt": "Failure {fail_turn_cnt}",
  "actual_output": "Actual output",
  "experiment_initializing": "Initializing the experiment",
  "experiment_comparison": "Experiment comparison",
  "experiment_comparison_initiation_failure": "Failed to initiate the experimental comparison",
  "cozeloop_open_evaluate_max_experiment_contrast_limit": "The maximum number of experiment comparisons cannot exceed {MAX_EXPERIMENT_CONTRAST_COUNT}. Please reselect.",
  "experiment_comparison_max_number": "The maximum number of experimental comparisons cannot exceed {num}. Please make a new selection.",
  "experiment_list": "Experiment list",
  "experiment_description": "Experiment description",
  "experiment_name": "Experiment name",
  "cozeloop_open_evaluate_experiment_details_export_success": "Experiment details export successful",
  "cozeloop_open_evaluate_experiment_details_export_failed": "Experiment details export failed",
  "cozeloop_open_evaluate_experiment_details_exporting": "Experiment details exporting",
  "refresh_after_experiment": "Once the experiment is completed, refresh to retry.",
  "experiment_supports_concurrent_eval_limitations": "The experiment supports concurrent execution of the entries in the evaluation set, but it is limited by the concurrency of the evaluation object and the TPM limit of the model that calls the evaluator. Here, the ideal maximum number of execution entries is set.",
  "experimental_group": "Experimental group",
  "evaluate_used_template": "Used Template",
  "evaluate_create_with_custom": "Create with Custom",
  "evaluate_biggest_animal_world": "What is the largest animal in the world",
  "evaluate_trial_run": "Trial Run",
  "testrun_require_fee": "The test run will consume resource points.",
  "cozeloop_open_evaluate_confirm_disable_redundant_field_validation": "Disable redundant field validation configuration?",
  "manual_score_calibration": "Whether to manually calibrate the score",
  "cozeloop_open_evaluate_multi_modal_data_in_cell_usage": "Suitable for managing mixed data of images, text and other modalities in the same cell.",
  "add_manually": "Add manually",
  "the_input_does_not_match_the_field_definition_of_the_column": "The input content does not meet the field definition of the column",
  "the_input_content_is_not_in_legal_json_format": "The input content is not in a valid JSON format",
  "input_content_limited_truncated": "The maximum length of the input content is {limitLength} characters. The excess part has been automatically truncated.",
  "dataset_capacity_exceeded": "The dataset capacity exceeds the limit",
  "data_processing_short": "Data processing",
  "data_structure": "Data structure",
  "evaluation_set_import_error_data_structure_tips": "The data structure does not meet the requirements and cannot be imported",
  "data_type": "Data type",
  "data_type_does_not_match_the_field_definition": "The data type does not match the field definition",
  "data_detail": "Data detail",
  "data_nesting_exceeds_limit": "Data nesting level exceeds limit",
  "data_item": "Data item",
  "data_item_index": "Data item {index}",
  "data_item_id": "Data item ID",
  "data_conversion_failed": "Data conversion failed",
  "data_total_count": "Total data count",
  "search_name": "Search for the name",
  "selected_fields_inconsistent": "The data types of the selected fields are inconsistent. Please select again.",
  "evaluate_test_taiwan_area_question": "What is the area of Taiwan Province?",
  "evaluate_test_taiwan_area_answer": "Taiwan Province consists of Taiwan Island and various islands, with a total area of about 36,000 square kilometers",
  "submit_form_problems": "Encounter problem when submitting the form",
  "submitted_successfully": "Submission successful",
  "evaluate_pre_submit_code_check": "Pre-submit Code Check",
  "submission_time": "Submission time:",
  "submit_new_version": "Submit a new version",
  "extract_data_structure": "Extract data structure",
  "extracting_the_data_structure_overwrite_tips": "Extracting the data structure will overwrite the original field definitions",
  "space_member_role_type_add_btn": "Add",
  "add_user_prompt": "Add User Prompt",
  "add_tag_column_to_data_details": "Add a tag column to the data details",
  "add_comparison_experiment": "Add comparison experiment",
  "add_column": "Add column",
  "add_evaluator": "Add evaluator",
  "add_data": "Add data",
  "add_data_item": "Add data item",
  "add_image_link": "Add a picture link",
  "add_child_item": "Add a sub-item",
  "cozeloop_open_evaluate_items_failed": "items, failed",
  "tiao_items": "items",
  "debugging_succeeded": "Debug succeed",
  "debug_failure": "Debug failed",
  "evaluate_debug_failed": "Debug Failed:",
  "evaluate_debug_failed_no_result": "Debug Failed: No Result Returned",
  "evaluate_debug_failed_no_evaluation_result": "Debug Failed: No Evaluation Result Returned",
  "evaluate_debug_no_evaluation_result": "Debug Returned No Evaluation Result",
  "skip_eval_object_execution_config": "Skip the execution configuration of the evaluation object, which is applicable to evaluation scenarios where the evaluation set already contains the actual output of the agent.",
  "evaluator_output_tips": "Extract data from the LLM through Function Call, and fix the output format of the evaluator as \"Score - Reason\".",
  "the_image_size_cannot_exceed_{size}_mb": "The size of the picture cannot exceed {size} MB",
  "cozeloop_open_evaluate_image_size_limit_20mb": "Image size cannot exceed 20MB",
  "exceed_max_image_size": "Image size exceeds limit",
  "image_address": "Image address",
  "get_image_failed": "Failed to get image",
  "exceed_max_image_count": "Image count exceeds limit",
  "image_external_link": "Picture - External link",
  "image_preview": "Image preview",
  "image_source_file": "Picture - Source file",
  "recommend_template_upload_tip": "It is recommended to upload 1 file using the template; CSV format is supported.",
  "refresh_after_all_tag_annotations_completed": "After completing all the data annotations for this tag, refresh and try again.",
  "completion_time": "Completion time",
  "later_than": "Later than",
  "user_wangwu": "Wang Wu",
  "prompt_variable_to_ensure_effect": "The evaluator prompt must have at least one variable to ensure the effectiveness of automatic evaluation",
  "evaluate_unnamed_template": "Unnamed Template",
  "no_results_found": "No relevant results were found",
  "no_matching_options_found": "No matching option was found",
  "evaluate_unknown_error": "Unknown Error",
  "knowledge_file_read_fail": "File read failed",
  "file_format_error": "File format error",
  "illegal_extension": "Illegal file extension",
  "system_error": "System error",
  "next_step_evaluation_object": "Next step: Evaluation object",
  "next_step_evaluation_set": "Next step: Evaluation set",
  "next_step_evaluator": "Next step: Evaluator",
  "next_one": "Next one",
  "download_template": "Download template",
  "cozeloop_open_evaluate_download_file": "Download file",
  "less_than": "Less than",
  "joke_king": "King of Jokes",
  "new_version_greater_than_current": "The new version must be greater than the current version",
  "new_prompt": "Create Prompt",
  "new_evaluation_set": "Create evaluation set",
  "new_evaluator": "Create evaluator",
  "new_experiment": "New experiment",
  "information_unsaved": "The information is not saved",
  "unsubmitted_changes": "Modifications are not submitted",
  "evaluate_select_template": "Select Template",
  "select_template": "Select a template",
  "cozeloop_open_evaluate_select_previous_eval_set_as_target": "Select the evaluation set configured in the previous step as the evaluation target, suitable for scenarios where the evaluation set already contains agent output.",
  "select_experiment": "Select an experiment",
  "skip_evaluator_config_agent_output_only": "Choose to skip the evaluator configuration. The experiment only obtains the actual output of the agent, which is suitable for the evaluation scenario of manual annotation.",
  "evaluation_set_builtin_example_data": "Sample data",
  "sample_data_format_error": "The format of the sample data is incorrect",
  "page_view": "Page view",
  "adjust_the_columns_with_workflow_api": "One-click adjustment of the columns in the evaluation set to the data format compatible with the workflow execution API",
  "remove_redundant_fields": "Remove redundant fields",
  "remove_experimental_group": "Remove the experimental group",
  "tag_added_placeholder1": "The tag {placeholder1} has been added.",
  "drilled_to_minimum_level_tips": "You have drilled down to the smallest level and cannot drill down further",
  "{num}_data_selected": "{num} pieces of data have been selected",
  "cozeloop_open_evaluate_selected_data_count": "Selected {placeholder1} data items",
  "x_data_item_selected": "{num} data item selected",
  "workflow_additional_fields": "Used to specify some additional fields required for the workflow",
  "expected_ideal_output": "Expected ideal output, which can serve as a reference standard for evaluation",
  "cozeloop_open_evaluate_preset_array_object_data_type": "Preset Array<Object> data type, Object data structure as follows. Suitable for managing mixed data of images, text and other modalities.",
  "preset_evaluator": "Preset evaluator",
  "evaluate_reason": "Reason:",
  "reason_is": "Reason: {reason}",
  "redundant_fields_allowed": "Allow redundant fields",
  "evaluate_running": "Running...",
  "aggregate_statistics_score_on_metrics": "In the experiment list, aggregate and calculate the scores of each experiment on the indicators.",
  "scroll_to_view_field_content_within_maximum_height": "Scroll within the maximum height to view the field content",
  "evaluate_no_test_data": "No Test Data",
  "no_export_record_yet": "There is no export record for now",
  "evaluate_no_config_info": "No Configuration Information",
  "no_evaluation_dataset": "No evaluation set",
  "no_evaluator": "No evaluator",
  "no_experiment": "No experiment",
  "no_data": "No data",
  "no_modification_to_submit": "No modification to submit",
  "earlier_than": "Earlier than",
  "expand_all_columns": "Expand all columns",
  "expand_all_data_items": "Expand all data items",
  "user_zhangsan": "Zhang San",
  "collapse_all_columns": "Collapse all columns",
  "collapse_all_data_items": "Collapse all data items",
  "line_chart": "Line chart",
  "this_is_a_cozebot": "This is a CozeBot",
  "evaluate_loading_code_evaluator_detail": "Loading Code Evaluator Detail",
  "loading_prompt_detail": "Loading Prompt details",
  "loading_field_mapping": "Loading field mappings",
  "uploading_pictures": "The picture is being uploaded",
  "cozeloop_open_evaluate_uploading_image": "Uploading image...",
  "evaluate_test_data_tutorial_tip": "It supports Python and JavaScript built - in libraries and some third - party libraries. For more usage instructions, please refer to...",
  "evaluation_set_import_files_tips": "Supported file formats: csv, zip, xlsx, xls. The maximum file size is 200MB. Only one file can be imported.",
  "evaluate_func_body": "Function Body",
  "execution_result": "Execution result",
  "status_running": "In execution",
  "measure_stat": "Indicator statistics",
  "retain_one_data_column": "Retain at least one column",
  "retain_one_data_item": "Retain at least one data item",
  "add_at_least_one_evaluator": "Add at least one evaluator",
  "retry_experiment": "Retry experiment",
  "evaluate_recheck": "Recheck",
  "bar_chart": "Bar chart",
  "append_data": "Append",
  "cozeloop_open_evaluate_autocomplete_confirm_overwrite_all_fields": "Auto-completing all fields in the data structure will overwrite original content. Confirm overwrite?",
  "cozeloop_open_evaluate_autocomplete_overwrites_original": "Auto-complete fields will overwrite original content",
  "field_completion": "Field completion",
  "field_content_is_not_limited_by_maximum_height": "The field content is not restricted by the maximum height",
  "field_mapping": "Field mapping",
  "total_number": "Total number of items",
  "total_count_placeholder1_success_count": "Total number: {placeholder1} (Successful: {success_turn_cnt}",
  "max_concurrent_execution_count": "Maximum number of concurrent executions",
  "max_concurrent_execution_count_limit": "The maximum number of concurrent executions supported is {EVAL_EXPERIMENT_CONCUR_COUNT_MAX}.",
  "keep_precision_num": "Keep at most {num} decimal places",
  "cozeloop_open_evaluate_max_four_decimal_places": "Maximum 4 decimal places",
  "max_add_x_evaluators": "Add a maximum of 5 evaluators",
  "max_support_columns": "Supports a maximum of {num} columns",
  "latest_version": "Latest version",
  "evaluation_set_input_tips": "Deliver it as input to the evaluation object"
}
